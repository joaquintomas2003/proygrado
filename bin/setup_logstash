#!/usr/bin/env bash
set -euo pipefail

LOGSTASH_ETC="${LOGSTASH_ETC:-/etc/logstash}"
ES_HOSTS_JSON="${ES_HOSTS_JSON:-[\"https://localhost:9200\"]}"
ES_USER="${ES_USER:-elastic}"
ES_PASS="${ES_PASS:-diciembre}"
SRC_ES_CA_CERT="${SRC_ES_CA_CERT:-/etc/elasticsearch/certs/http_ca.crt}"
ES_CA_CERT="${ES_CA_CERT:-/etc/logstash/certs/http_ca.crt}"

# ← you asked to call the pipeline "int-metrics"
PIPELINE_ID="${PIPELINE_ID:-int-metrics}"
PORT_BEATS="${PORT_BEATS:-5044}"
HOPS_INDEX_PATTERN="${HOPS_INDEX_PATTERN:-int-metrics-%{+YYYY.MM.dd}}"
NFP_INDEX_PATTERN="${NFP_INDEX_PATTERN:-nfp-logs-%{+YYYY.MM.dd}}"
PIPELINE_WORKERS="${PIPELINE_WORKERS:-4}"
PQ_BYTES="${PQ_BYTES:-4gb}"

PIPELINES_FILE="$LOGSTASH_ETC/pipelines.yml"
CONF_DIR="$LOGSTASH_ETC/conf.d"
CONF_FILE="$CONF_DIR/30-int-metrics.conf"
LOGSTASH_YML="$LOGSTASH_ETC/logstash.yml"
LS_BIN="/usr/share/logstash/bin/logstash"

ts() { date +%Y%m%d%H%M%S; }

echo "→ Ensuring Logstash config directories exist..."
sudo mkdir -p "$CONF_DIR" /etc/logstash/certs

backup_if_exists () {
  local f="$1"
  if sudo test -f "$f"; then
    local bak="${f}.bak.$(ts)"
    echo "→ Backing up $f to $bak"
    sudo cp -a "$f" "$bak"
  fi
}
backup_if_exists "$PIPELINES_FILE"
backup_if_exists "$CONF_FILE"
backup_if_exists "$LOGSTASH_YML"

# --- Ensure CA cert is present for Logstash ---
if ! sudo test -r "$ES_CA_CERT"; then
  echo "→ Installing CA cert for Logstash..."
  if ! sudo test -r "$SRC_ES_CA_CERT"; then
    echo "✗ Source CA not readable: $SRC_ES_CA_CERT" >&2
    exit 1
  fi
  sudo install -m 0644 "$SRC_ES_CA_CERT" "$ES_CA_CERT"
fi
sudo chmod 0644 "$ES_CA_CERT"
sudo chmod 0755 /etc/logstash /etc/logstash/certs

echo "→ Writing pipelines.yml (overwriting)..."
sudo tee "$PIPELINES_FILE" >/dev/null <<YML
- pipeline.id: ${PIPELINE_ID}
  path.config: "${CONF_DIR}/*.conf"
  pipeline.workers: ${PIPELINE_WORKERS}
  queue.type: persisted
YML

echo "→ Writing ${CONF_FILE} (overwriting)..."
sudo tee "$CONF_FILE" >/dev/null <<CONF
input {
  beats { port => ${PORT_BEATS} }
}

filter {
  if [event][dataset] == "int.metrics" {
    #
    # Keep both arrays in the event, and ALSO create flat arrays like:
    #   int.hop_latency_latest, int.hop_latency_average, int.node_id_latest, ...
    #
    ruby {
      code => '
        def pull(arr, key)
          return [] unless arr.is_a?(Array)
          arr.map{|h| h.is_a?(Hash) ? h[key] : nil}.compact
        end

        latest  = event.get("[int][latest]")  || []
        average = event.get("[int][average]") || []

        event.set("[int][node_id_latest]",             pull(latest,  "node_id"))
        event.set("[int][hop_latency_latest]",         pull(latest,  "hop_latency"))
        event.set("[int][queue_occupancy_latest]",     pull(latest,  "queue_occupancy"))
        event.set("[int][egress_interface_tx_latest]", pull(latest,  "egress_interface_tx"))

        event.set("[int][node_id_average]",             pull(average, "node_id"))
        event.set("[int][hop_latency_average]",         pull(average, "hop_latency"))
        event.set("[int][queue_occupancy_average]",     pull(average, "queue_occupancy"))
        event.set("[int][egress_interface_tx_average]", pull(average, "egress_interface_tx"))

        # Convenience scalars
        event.set("[int][hops_count_latest]",  (latest.is_a?(Array)  ? latest.size  : 0))
        event.set("[int][hops_count_average]", (average.is_a?(Array) ? average.size : 0))

        # Per-doc averages (float)
        lats_l = event.get("[int][hop_latency_latest]")  || []
        lats_a = event.get("[int][hop_latency_average]") || []
        if lats_l.any?
          sum = 0.0; lats_l.each{|v| sum += v.to_f rescue nil }
          event.set("[int][hop_latency_avg_latest]",  sum / lats_l.length)
        end
        if lats_a.any?
          sum = 0.0; lats_a.each{|v| sum += v.to_f rescue nil }
          event.set("[int][hop_latency_avg_average]", sum / lats_a.length)
        end
      '
    }

    # (Optional) Sanity: ensure numeric types where possible
    mutate {
      convert => {
        "[int][hops_count_latest]"           => "integer"
        "[int][hops_count_average]"          => "integer"
        "[int][hop_latency_avg_latest]"      => "float"
        "[int][hop_latency_avg_average]"     => "float"
      }
    }
  }
}

output {
  if [event][dataset] == "int.metrics" {
    elasticsearch {
      hosts                       => ${ES_HOSTS_JSON}
      user                        => "${ES_USER}"
      password                    => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${ES_CA_CERT}"]
      index                       => "${HOPS_INDEX_PATTERN}"
    }
  } else if [event][dataset] == "nfp.logs" {
    elasticsearch {
      hosts                       => ${ES_HOSTS_JSON}
      user                        => "${ES_USER}"
      password                    => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${ES_CA_CERT}"]
      index                       => "${NFP_INDEX_PATTERN}"
    }
  }
}
CONF

echo "→ Enabling persistent queues in logstash.yml (idempotent)..."
if sudo grep -qE '^\s*queue\.type:' "$LOGSTASH_YML"; then
  sudo sed -i 's/^\s*queue\.type:.*/queue.type: persisted/' "$LOGSTASH_YML"
else
  echo "queue.type: persisted" | sudo tee -a "$LOGSTASH_YML" >/dev/null
fi

if sudo grep -qE '^\s*queue\.max_bytes:' "$LOGSTASH_YML"; then
  sudo sed -i "s/^\s*queue\.max_bytes:.*/queue.max_bytes: ${PQ_BYTES}/" "$LOGSTASH_YML"
else
  echo "queue.max_bytes: ${PQ_BYTES}" | sudo tee -a "$LOGSTASH_YML" >/dev/null
fi

echo "→ Validating Logstash configuration..."
sudo -u logstash "$LS_BIN" --path.settings "$LOGSTASH_ETC" --config.test_and_exit

echo "→ Restarting Logstash..."
sudo systemctl restart logstash

echo "→ Tail Logstash logs (Ctrl-C to exit):"
sudo journalctl -u logstash -f
